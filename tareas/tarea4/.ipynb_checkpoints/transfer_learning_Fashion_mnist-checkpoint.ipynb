{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Fasion MNIST\n",
    "\n",
    "Vamos a reentrenar nuestra VGG pero con el conjunto de datos de moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.utils                import to_categorical\n",
    "from tensorflow                            import keras \n",
    "from tensorflow.keras                      import backend as K\n",
    "from tensorflow.keras.preprocessing.image  import load_img\n",
    "from tensorflow.keras.layers               import Input, Dense, Flatten, Lambda, Dropout\n",
    "from tensorflow.keras.layers               import AveragePooling2D\n",
    "from tensorflow.keras.optimizers           import Adam\n",
    "from tensorflow.keras.models               import Sequential, Model, load_model\n",
    "from tensorflow.keras                      import applications  \n",
    "from tensorflow.keras.datasets             import fashion_mnist\n",
    "from tensorflow.keras                      import layers\n",
    "from tensorflow.keras.applications.vgg16   import VGG16\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "((X_tr, y_tr),(X_ts,y_ts))= tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ts = X_ts.reshape(-1,28,28,1).astype('float32') / 255\n",
    "X_tr = X_tr.reshape(-1,28,28,1).astype('float32') / 255\n",
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ts.reshape(-1,28,28,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_ts = to_categorical(y_ts)\n",
    "Y_tr = to_categorical(y_tr)\n",
    "Y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicaciones de Keras\n",
    "\n",
    "![Aplicaciones](./keras_aplications.png)\n",
    "\n",
    "Keras ya tiene modelos preentrenados que pueden ver en [keras applications](https://keras.io/api/applications/) que tiene varias redes, entre ellas VGG, pero también muchas otras muy sofisticadas que usarán dependiendo de su problema.\n",
    "\n",
    "No estaría mal que las revisaran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 297,578\n",
      "Trainable params: 297,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG16(input_shape=(32,32,3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "for ly in vgg.layers:\n",
    "    ly.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 297,578\n",
      "Trainable params: 297,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelo = load_model('conv_digits.h5')\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo = Sequential()\n",
    "for ly in range(len(modelo.layers)-3):\n",
    "    nuevo.add(modelo.layers[ly])\n",
    "\n",
    "for ly in nuevo.layers:\n",
    "    ly.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "=================================================================\n",
      "Total params: 1,248\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nuevo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo.add(Dense(128, activation='tanh', name=\"densa_a\" ))\n",
    "nuevo.add(Dropout(0.5, name=\"dropout_a\"))\n",
    "nuevo.add(Dense(64, activation='tanh', name=\"densa_b\" ))\n",
    "nuevo.add((Dropout(0.25, name=\"dropout_b\")))\n",
    "nuevo.add(Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "densa_a (Dense)              (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dropout_a (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "densa_b (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_b (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 305,194\n",
      "Trainable params: 303,946\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nuevo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=1e-3)\n",
    "nuevo.compile(\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    optimizer = opt,\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "Epoch 2/10\n",
      "Epoch 3/10\n",
      "Epoch 4/10\n",
      "Epoch 5/10\n",
      "Epoch 6/10\n",
      "Epoch 7/10\n",
      "Epoch 8/10\n",
      "Epoch 9/10\n",
      "Epoch 10/10\n"
     ]
    }
   ],
   "source": [
    "H = nuevo.fit(x=X_tr, y=Y_tr,\n",
    "             batch_size=32,\n",
    "             epochs=10,\n",
    "             verbose=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5953935828>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(H.history['accuracy'])\n",
    "plt.plot(H.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 531us/sample - loss: 2.3039 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.303914120864868, 0.1]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuevo.evaluate(X_ts,Y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
